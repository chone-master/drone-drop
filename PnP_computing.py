import cv2
import cv2.aruco as aruco
import numpy as np
import math


def get_dji_camera_matrix(width, height, dfov_deg=84.0):
    """
    æ ¹æ® DJI ç›¸æœºçš„ DFOV (é€šå¸¸ 84åº¦) å’Œå›¾åƒåˆ†è¾¨ç‡ï¼Œè®¡ç®—å†…å‚çŸ©é˜µ
    """
    # 1. è®¡ç®—å¯¹è§’çº¿åƒç´ é•¿åº¦
    diagonal_pixels = math.sqrt(width ** 2 + height ** 2)

    # 2. è®¡ç®—ç„¦è· (åƒç´ å•ä½)
    # formula: f_pixels = (diagonal_pixels / 2) / tan(DFOV / 2)
    fov_rad = math.radians(dfov_deg)
    focal_length_px = (diagonal_pixels / 2) / math.tan(fov_rad / 2)

    # 3. æ„é€ çŸ©é˜µ
    # [fx,  0, cx]
    # [ 0, fy, cy]
    # [ 0,  0,  1]
    center_x = width / 2
    center_y = height / 2

    # å‡è®¾åƒç´ æ˜¯æ­£æ–¹å½¢ï¼Œfx = fy
    camera_matrix = np.array([
        [focal_length_px, 0, center_x],
        [0, focal_length_px, center_y],
        [0, 0, 1]
    ], dtype=np.float32)

    dist_coeffs = np.zeros((5, 1))  # å¤§ç–†æ¨æµé€šå¸¸å·²ç»åšè¿‡ç•¸å˜çŸ«æ­£ï¼Œè¿™é‡Œè®¾ä¸º0å³å¯
    return camera_matrix, dist_coeffs


def main():
    # ================= é…ç½®åŒºåŸŸ =================
    image_path = "tag3.png"  # ä½ çš„æµ‹è¯•å›¾ç‰‡

    # çœŸå®ç‰©ç†å°ºå¯¸ (å•ä½ï¼šç±³)
    TAG_SIZE_BIG = 0.60  # ç”¨æˆ·æŒ‡å®šï¼š60cm
    TAG_SIZE_SMALL = 0.12  # ä¼°ç®—ï¼šå»ºè®®å®æµ‹ä¸€ä¸‹å†…éƒ¨å°ç çš„è¾¹é•¿

    # ä½ çš„æ¨æµåˆ†è¾¨ç‡ (å¾ˆé‡è¦ï¼Orin æ”¶åˆ°çš„æ˜¯å¤šå°‘åˆ†è¾¨ç‡å°±å¡«å¤šå°‘)
    STREAM_W = 1400
    STREAM_H = 1327
    # ===========================================

    # 1. ç”Ÿæˆç›¸æœºå†…å‚
    camera_matrix, dist_coeffs = get_dji_camera_matrix(STREAM_W, STREAM_H)
    print(f"ğŸ“· ç›¸æœºå†…å‚è®¡ç®—å®Œæ¯• (fx={camera_matrix[0][0]:.1f})")

    # 2. å‡†å¤‡æ£€æµ‹å™¨
    aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_36h11)
    parameters = aruco.DetectorParameters()
    detector = aruco.ArucoDetector(aruco_dict, parameters)

    # è¯»å–å›¾ç‰‡ (å®é™…åº”ç”¨ä¸­è¿™é‡Œæ˜¯ cap.read())
    frame = cv2.imread(image_path)
    if frame is None:
        print("âŒ æ— æ³•è¯»å–å›¾ç‰‡")
        return

    # å¦‚æœå›¾ç‰‡å°ºå¯¸å’Œè®¾å®šçš„æµåˆ†è¾¨ç‡ä¸ä¸€è‡´ï¼Œå¼ºè¡Œç¼©æ”¾æ¨¡æ‹ŸçœŸå®æƒ…å†µ
    if frame.shape[1] != STREAM_W:
        frame = cv2.resize(frame, (STREAM_W, STREAM_H))

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, rejected = detector.detectMarkers(gray)

    if ids is not None:
        print(f"âœ¨ æ£€æµ‹åˆ° {len(ids)} ä¸ª Tag")

        # 3. å®šä¹‰ Tag çš„ 3D åæ ‡ç‚¹ (ä»¥ Tag ä¸­å¿ƒä¸º 0,0,0)
        def get_obj_points(size):
            half = size / 2
            return np.array([
                [-half, half, 0], [half, half, 0], [half, -half, 0], [-half, -half, 0]
            ], dtype=np.float32)

        for i in range(len(ids)):
            current_id = ids[i][0]

            # ç­–ç•¥ï¼šæ ¹æ® ID åˆ‡æ¢å°ºå¯¸
            if current_id in [571, 576]:  # å°ç 
                obj_points = get_obj_points(TAG_SIZE_SMALL)
                tag_name = "å°ç  (é™è½)"
            else:  # å¤§ç 
                obj_points = get_obj_points(TAG_SIZE_BIG)
                tag_name = "å¤§ç  (å®šä½)"

            # PnP è§£ç®—
            # solvePnP æ¥æ”¶ï¼š3Dç‚¹, 2Dè§’ç‚¹, å†…å‚, ç•¸å˜
            ret, rvec, tvec = cv2.solvePnP(obj_points, corners[i], camera_matrix, dist_coeffs)

            # --- è¿™ä¸€æ­¥æœ€å…³é”®ï¼šåæ ‡ç³»è½¬æ¢ ---
            # tvec é‡Œçš„æ•°æ®æ˜¯ã€ç›¸æœºåæ ‡ç³»ã€‘ï¼š
            # x_cam: å³ä¸ºæ­£
            # y_cam: ä¸‹ä¸ºæ­£
            # z_cam: å‰ä¸ºæ­£ (å³é«˜åº¦)

            x_cam = tvec[0][0]
            y_cam = tvec[1][0]
            z_cam = tvec[2][0]  # è¿™å°±æ˜¯é«˜åº¦

            # è½¬æ¢ä¸ºã€æ— äººæœºæœºä½“åæ ‡ç³»ã€‘(Body Frame)
            # å‡è®¾ç›¸æœºå‚ç›´æœä¸‹å®‰è£…ï¼Œæœºå¤´æœå‘ç”»é¢ä¸Šæ–¹ï¼š
            # 1. å›¾åƒçš„å³ (x_cam) -> æ— äººæœºçš„å³ (Roll) -> éœ€è¦å‘å³é£
            # 2. å›¾åƒçš„ä¸‹ (y_cam) -> æ— äººæœºçš„å (Pitch) -> éœ€è¦å‘åé£

            # åå·® (Error) = ç›®æ ‡ - å½“å‰
            # ç›®æ ‡æ˜¯ (0,0)ï¼Œæ‰€ä»¥ Error = 0 - pos
            err_roll = -x_cam  # åå·®ä¸ºè´Ÿï¼Œè¡¨ç¤ºè¦å‘å·¦ä¿®ï¼›åå·®ä¸ºæ­£ï¼Œå‘å³ä¿®
            err_pitch = y_cam  # æ³¨æ„æ–¹å‘ï¼šå¦‚æœ Tag åœ¨ç”»é¢ä¸‹æ–¹ (y_cam>0)ï¼Œè¯´æ˜é£æœºå¤ªé å‰äº†ï¼Œéœ€è¦å‘åé£

            print(f"--------------------------------")
            print(f"ğŸ¯ ç›®æ ‡: {tag_name} [ID: {current_id}]")
            print(f"   ğŸ“ é«˜åº¦ (Z): {z_cam:.2f} m")
            print(f"   â†”ï¸  æ¨ªå‘åå·® (Cam X): {x_cam:.2f} m")
            print(f"   â†•ï¸  çºµå‘åå·® (Cam Y): {y_cam:.2f} m")
            print(f"   ğŸ‘‰ æŒ‡ä»¤é¢„æµ‹: å‘{'å·¦' if err_roll > 0 else 'å³'}é£ {abs(err_roll):.2f}m, "
                  f"å‘{'å‰' if err_pitch > 0 else 'å'}é£ {abs(err_pitch):.2f}m")

            # ç”»è½´
            cv2.drawFrameAxes(frame, camera_matrix, dist_coeffs, rvec, tvec, 0.3)

        # æ˜¾ç¤º
        cv2.imshow("Landing View", cv2.resize(frame, (960, 540)))
        cv2.waitKey(0)
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()