import cv2
import cv2.aruco as aruco
import numpy as np
import math
import time
import socket
import json
import threading
import queue
import os

# ================= 1. é…ç½®åŒºåŸŸ =================

# --- RTSP è¿æ¥é…ç½® ---
RTSP_USERNAME = "djiuser"
RTSP_PASSWORD = "123456"
RTSP_IP = "192.168.31.106"  # é¥æ§å™¨ IP (M3E/M30 é€šå¸¸æ˜¯è¿™ä¸ª)
RTSP_PORT = 8554
RTSP_PATH = "streaming/live/1"

# --- å®‰å“ç«¯é€šä¿¡é…ç½® ---
ANDROID_IP = "192.168.31.106"
ANDROID_PORT = 8888

# --- ç‰©ç†å°ºå¯¸ä¸å¸ƒå±€ ---
TAG_SIZE_BIG = 0.515
TAG_SIZE_SMALL = 0.096

TAG_LAYOUT = {
    0: np.array([0.0, 0.0, 0.0]),
    576: np.array([0.075, 0.0015, 0.0]),
    571: np.array([-0.09, -0.052, 0.0])
}

# --- åˆ†è¾¨ç‡è®¾ç½® ---
# è¾“å…¥æµåˆ†è¾¨ç‡ (DJI M3E é€šå¸¸æ˜¯ 4K æˆ– 1080P)
# æˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨æŒ‡å®šè¾“å…¥åˆ†è¾¨ç‡ï¼ŒOpenCV ä¼šè‡ªåŠ¨è¯†åˆ«
# PROCESS_W/H æ˜¯ç®—æ³•å¤„ç†æ—¶çš„åˆ†è¾¨ç‡ï¼Œå»ºè®® 1920x1080 ä»¥å¹³è¡¡é€Ÿåº¦ä¸ç²¾åº¦
PROCESS_W = 1920
PROCESS_H = 1080
# PROCESS_W = 3840
# PROCESS_H = 2160

DFOV_DEG = 84.0


# ================= 2. çº¿ç¨‹å·¥å…·ç±» =================

class RTSPStreamLoader:
    """
    RTSP ä¸“ç”¨æ‹‰æµçº¿ç¨‹ï¼š
    1. è‡ªåŠ¨æ–­çº¿é‡è¿
    2. æ°¸è¿œåªä¿ç•™æœ€æ–°ä¸€å¸§ (ä¸¢å¼ƒæ—§å¸§)
    """

    def __init__(self, rtsp_url):
        self.rtsp_url = rtsp_url
        self.lock = threading.Lock()
        self.frame = None
        self.stopped = False
        self.connect_success = False

        # å¼ºåˆ¶ä½¿ç”¨ UDP ä¼ è¾“ä»¥é™ä½å»¶è¿Ÿ
        os.environ["OPENCV_FFMPEG_CAPTURE_OPTIONS"] = "rtsp_transport;udp"

        print(f"ğŸ“¡ æ­£åœ¨è¿æ¥ RTSP: {rtsp_url} ...")
        self.connect()

    def connect(self):
        if hasattr(self, 'cap') and self.cap:
            self.cap.release()

        self.cap = cv2.VideoCapture(self.rtsp_url)
        # ç¼“å†²åŒºè®¾ç½®ä¸º1ï¼Œå°½å¯èƒ½å‡å°‘ç§¯å‹
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

        if self.cap.isOpened():
            self.connect_success = True
            print("âœ… RTSP è¿æ¥æˆåŠŸï¼")
        else:
            print("âŒ RTSP è¿æ¥å¤±è´¥ï¼Œå°†åœ¨åå°é‡è¯•...")

    def start(self):
        threading.Thread(target=self.update, args=(), daemon=True).start()
        return self

    def update(self):
        while not self.stopped:
            if not self.cap.isOpened():
                time.sleep(1)
                self.connect()
                continue

            ret, frame = self.cap.read()
            if ret:
                with self.lock:
                    self.frame = frame
            else:
                # è¯»å–å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æ–­æµï¼‰
                print("âš ï¸ RTSP æ— æ•°æ®ï¼Œå°è¯•é‡è¿...")
                time.sleep(0.5)
                self.connect()

    def get_frame(self):
        with self.lock:
            return self.frame.copy() if self.frame is not None else None

    def stop(self):
        self.stopped = True
        if self.cap: self.cap.release()


class UDPSender:
    """
    UDP å‘é€çº¿ç¨‹ï¼š
    é¿å…ç½‘ç»œ IO é˜»å¡ä¸»çº¿ç¨‹çš„å›¾åƒå¤„ç†
    """

    def __init__(self, ip, port):
        self.target_addr = (ip, port)
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.queue = queue.Queue(maxsize=1)  # åªå­˜æœ€æ–°çš„ä¸€æ¡
        self.stopped = False
        print(f"ğŸ“¡ UDP å‘é€æœåŠ¡å¯åŠ¨ -> {ip}:{port}")

    def start(self):
        threading.Thread(target=self.run, args=(), daemon=True).start()
        return self

    def send_async(self, data):
        if self.stopped: return
        try:
            # å¦‚æœé˜Ÿåˆ—æ»¡ï¼Œä¸¢å¼ƒæ—§çš„ï¼Œæ”¾å…¥æ–°çš„
            if self.queue.full():
                try:
                    self.queue.get_nowait()
                except:
                    pass
            self.queue.put_nowait(data)
        except:
            pass

    def run(self):
        while not self.stopped:
            try:
                data = self.queue.get(timeout=0.5)
                msg = json.dumps(data).encode('utf-8')
                self.sock.sendto(msg, self.target_addr)
            except queue.Empty:
                continue
            except Exception as e:
                print(f"UDP Error: {e}")

    def stop(self):
        self.stopped = True
        self.sock.close()


# ================= 3. ç®—æ³•å·¥å…·ç±» =================

def apply_deadband(val):
    """æ­»åŒºæ§åˆ¶ï¼šé˜²æ­¢ç”±äºå™ªç‚¹å¯¼è‡´æ— äººæœºå¾®å°æŠ–åŠ¨"""
    MIN_MOVE_SPEED = 0.12  # æœ€å°åŠ¨ä½œé€Ÿåº¦
    STOP_THRESHOLD = 0.05  # æ­»åŒºé˜ˆå€¼

    if abs(val) < STOP_THRESHOLD:
        return 0.0
    elif abs(val) < MIN_MOVE_SPEED:
        return math.copysign(MIN_MOVE_SPEED, val)
    else:
        return val


class PIDController:
    def __init__(self, kp, ki, kd, max_out=0.5):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.max_out = max_out
        self.prev_error = 0
        self.integral = 0

    def update(self, error, dt):
        if dt <= 0: dt = 0.033

        p_term = self.kp * error
        d_term = self.kd * (error - self.prev_error) / dt

        self.integral += error * dt
        self.integral = np.clip(self.integral, -0.5, 0.5)
        i_term = self.ki * self.integral

        output = p_term + i_term + d_term
        self.prev_error = error
        return np.clip(output, -self.max_out, self.max_out)


class EnhancedTagDetector:
    """
    ã€ä¿ç•™å¢å¼ºæ£€æµ‹ã€‘
    é›†æˆå£ç½©æ³•å’Œè†¨èƒ€æ³•ï¼Œä¿è¯åœ¨å¤æ‚ç¯å¢ƒä¸‹ä¹Ÿèƒ½è¯†åˆ«
    """

    def __init__(self, width, height, dfov_deg):
        self.camera_matrix, self.dist_coeffs = self._get_camera_matrix(width, height, dfov_deg)
        self.aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_36h11)
        self.parameters = aruco.DetectorParameters()
        self.parameters.cornerRefinementMethod = aruco.CORNER_REFINE_SUBPIX
        self.detector = aruco.ArucoDetector(self.aruco_dict, self.parameters)

    def _get_camera_matrix(self, width, height, dfov_deg):
        diagonal_pixels = math.sqrt(width ** 2 + height ** 2)
        fov_rad = math.radians(dfov_deg)
        f_px = (diagonal_pixels / 2) / math.tan(fov_rad / 2)
        K = np.array([[f_px, 0, width / 2], [0, f_px, height / 2], [0, 0, 1]], dtype=np.float32)
        D = np.zeros((5, 1))
        return K, D

    def detect_with_enhancement(self, frame):
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 1. å¸¸è§„æ£€æµ‹
        corners, ids, _ = self.detector.detectMarkers(gray)
        final_corners = list(corners) if corners else []
        final_ids = list(ids[:, 0]) if ids is not None else []

        has_big_tag = 0 in final_ids if final_ids else False

        # 2. å£ç½©æ³•
        if not has_big_tag:
            corners_mask, ids_mask = self._mask_small_tags_method(gray, final_corners, final_ids)
            if ids_mask is not None and 0 in ids_mask:
                final_corners.extend(corners_mask)
                final_ids.extend(ids_mask[:, 0])
                has_big_tag = True

        # 3. è†¨èƒ€æ³•
        if not has_big_tag:
            corners_dilate, ids_dilate = self._dilate_method(gray)
            if ids_dilate is not None and 0 in ids_dilate:
                final_corners.extend(corners_dilate)
                final_ids.extend(ids_dilate[:, 0])

        if not final_ids: return tuple(), None
        return tuple(final_corners), np.array(final_ids).reshape(-1, 1)

    def _mask_small_tags_method(self, gray, existing_corners, existing_ids):
        masked_gray = gray.copy()
        small_tags_corners = []
        if existing_ids:
            for i, id_val in enumerate(existing_ids):
                if id_val in [571, 576]:
                    small_tags_corners.append(existing_corners[i])
        for corner_set in small_tags_corners:
            pts = corner_set[0]
            center = np.mean(pts, axis=0)
            expanded_pts = (pts - center) * 1.6 + center
            cv2.fillPoly(masked_gray, [expanded_pts.astype(np.int32)], 255)
        corners, ids, _ = self.detector.detectMarkers(masked_gray)
        if ids is not None and 0 in ids:
            return [corners[np.where(ids == 0)[0][0]]], np.array([[0]])
        return None, None

    def _dilate_method(self, gray):
        k_size = int(gray.shape[1] * 0.015)
        if k_size % 2 == 0: k_size += 1
        dilated = cv2.dilate(gray, np.ones((k_size, k_size), np.uint8), iterations=1)
        corners, ids, _ = self.detector.detectMarkers(dilated)
        if ids is not None and 0 in ids:
            return [corners[np.where(ids == 0)[0][0]]], np.array([[0]])
        return None, None

    def solve_position(self, corners, ids):
        if ids is None: return None
        positions = []
        for i, id_val in enumerate(ids[:, 0]):
            curr_id = int(id_val)
            size = TAG_SIZE_SMALL if curr_id in [571, 576] else TAG_SIZE_BIG
            obj_pts = np.array([[-size / 2, size / 2, 0], [size / 2, size / 2, 0],
                                [size / 2, -size / 2, 0], [-size / 2, -size / 2, 0]], dtype=np.float32)

            # ä½¿ç”¨åŸºç¡€ solvePnP (ä¸ä½¿ç”¨ IPPE ä»¥é¿å…æŠ–åŠ¨ï¼Œæˆ–æŒ‰éœ€å¼€å¯)
            _, rvec, tvec = cv2.solvePnP(obj_pts, corners[i], self.camera_matrix, self.dist_coeffs)
            if curr_id in TAG_LAYOUT:
                positions.append(tvec.flatten() - TAG_LAYOUT[curr_id])

        if positions: return np.mean(positions, axis=0)
        return None


# ================= 4. ä¸»æµç¨‹ =================
def main():
    # 1. å¯åŠ¨ç¡¬ä»¶çº¿ç¨‹
    rtsp_url = f"rtsp://{RTSP_USERNAME}:{RTSP_PASSWORD}@{RTSP_IP}:{RTSP_PORT}/{RTSP_PATH}"
    stream_loader = RTSPStreamLoader(rtsp_url).start()
    udp_sender = UDPSender(ANDROID_IP, ANDROID_PORT).start()

    # 2. åˆå§‹åŒ–å¢å¼ºå‹æ£€æµ‹å™¨
    detector = EnhancedTagDetector(PROCESS_W, PROCESS_H, DFOV_DEG)

    # 3. åˆå§‹åŒ– PID
    pid_roll = PIDController(kp=1.0, ki=0.0, kd=0.1)
    pid_pitch = PIDController(kp=1.0, ki=0.0, kd=0.1)

    print("ğŸš€ èåˆç³»ç»Ÿå…¨é€Ÿè¿è¡Œä¸­... (ç­‰å¾…è§†é¢‘æµ)")

    # ç­‰å¾…ç¬¬ä¸€å¸§
    while stream_loader.get_frame() is None:
        time.sleep(0.1)

    last_time = time.time()
    # ã€æ–°å¢ã€‘ç”¨äºè®°å¿†æœ€åçš„é«˜åº¦
    last_valid_height = 10.0  # åˆå§‹å€¼ç»™å¤§ä¸€ç‚¹ï¼Œé˜²æ­¢è¯¯åˆ¤
    # ã€æ–°å¢ã€‘ç›²é™è®¡æ—¶å™¨ï¼ˆå¯é€‰ï¼Œé˜²æ­¢æ— é™ç›²é™ï¼‰
    blind_land_start_time = 0
    try:
        while True:
            # --- A. è·å–æœ€æ–°å¸§ ---
            frame = stream_loader.get_frame()
            if frame is None: continue

            # è®¡ç®— dt
            current_time = time.time()
            dt = current_time - last_time
            last_time = current_time

            # ç¼©æ”¾è‡³ 1080P å¤„ç† (æå‡é€Ÿåº¦)
            if frame.shape[1] != PROCESS_W:
                frame = cv2.resize(frame, (PROCESS_W, PROCESS_H))

            # --- B. å¢å¼ºè§†è§‰å¤„ç† ---
            corners, ids = detector.detect_with_enhancement(frame)
            final_pos = detector.solve_position(corners, ids)

            # --- C. PID è®¡ç®—ä¸æ­»åŒºæ§åˆ¶ ---
            cmd_roll, cmd_pitch, vel_z = 0.0, 0.0, 0.0
            if final_pos is not None:
                x, y, z = final_pos
                # ã€å…³é”®ã€‘æ—¶åˆ»æ›´æ–°è®°å¿†
                last_valid_height = z
                blind_land_start_time = 0  # é‡ç½®ç›²é™è®¡æ—¶
                # åŸå§‹ PID è¾“å‡º
                raw_roll = pid_roll.update(0 - x, dt=dt) * -1
                raw_pitch = pid_pitch.update(0 - y, dt=dt)

                # åº”ç”¨æ­»åŒº (é˜²æ­¢å¾®å°æŠ–åŠ¨)
                cmd_roll = apply_deadband(raw_roll)
                cmd_pitch = apply_deadband(raw_pitch)

                # ä¸‹é™é€»è¾‘
                horizontal_error = math.sqrt(x ** 2 + y ** 2)

                if z < 0.4:
                    vel_z = -0.15  # å¼ºåˆ¶æ…¢é€Ÿè§¦åœ°
                    # åœ¨æä½ç©ºï¼Œä¸ºäº†é˜²æ­¢ç”»é¢è¾¹ç¼˜ç•¸å˜å¯¼è‡´çš„è¯¯ä¿®ï¼Œå¯ä»¥é”æ­»æ°´å¹³æ§åˆ¶
                    # cmd_r = 0.0
                    # cmd_p = 0.0
                elif horizontal_error < 0.3:
                    vel_z = max(-0.3, -z * 0.3)  # æ¯”ä¾‹ä¸‹é™
                else:
                    vel_z = 0.0

                # --- ç»˜åˆ¶ UI (ä¿ç•™ä½ å–œæ¬¢çš„å¤§å­—ä½“é£æ ¼) ---
                aruco.drawDetectedMarkers(frame, corners, ids)

                # ä¸­å¿ƒç‚¹ä¸è¿çº¿
                cx = int(PROCESS_W / 2 + x * (detector.camera_matrix[0][0] / z))
                cy = int(PROCESS_H / 2 + y * (detector.camera_matrix[1][1] / z))
                screen_cx, screen_cy = PROCESS_W // 2, PROCESS_H // 2

                cv2.line(frame, (screen_cx, screen_cy), (cx, cy), (0, 255, 0), 3)
                cv2.circle(frame, (cx, cy), 15, (0, 0, 255), -1)

                # æ–‡å­—ä¿¡æ¯
                info_text = [
                    f"H: {z:.2f}m",
                    f"Err: {horizontal_error:.2f}m",
                    f"R: {cmd_roll:.2f} P: {cmd_pitch:.2f}"
                ]
                for idx, text in enumerate(info_text):
                    cv2.putText(frame, text, (30, 80 + idx * 60),
                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3)

                # ç®­å¤´æŒ‡ç¤º
                arrow_len = 150
                end_x = int(screen_cx + cmd_roll * arrow_len)
                end_y = int(screen_cy - cmd_pitch * arrow_len)
                cv2.arrowedLine(frame, (screen_cx, screen_cy), (end_x, end_y), (255, 0, 255), 8)
            else:
                # ---------------------------
                # ğŸ”´ åœºæ™¯ B: ä¸¢å¤±ç›®æ ‡ (çœ‹ä¸è§ç äº†!)
                # --------------------------
                # åˆ¤æ–­æ˜¯â€œé«˜ç©ºä¸¢å¤±â€è¿˜æ˜¯â€œä½ç©ºä¸¢å¤±â€
                if last_valid_height < 0.5:
                    # === ã€æ ¸å¿ƒã€‘ä½ç©ºç›²é™é€»è¾‘ ===
                    print(f"ğŸ“‰ è¿›å…¥ç›²é™æ¨¡å¼ (æœ€åé«˜åº¦: {last_valid_height:.2f}m)")
                    # 1. æ°´å¹³æ–¹å‘ï¼šç»å¯¹ä¸åŠ¨ (ç›¸ä¿¡ä¹‹å‰çš„å¯¹å‡†)
                    cmd_r = 0.0
                    cmd_p = 0.0
                    # 2. å‚ç›´æ–¹å‘ï¼šç»™ä¸€ä¸ªèƒ½å¤Ÿè§¦åœ°çš„é€Ÿåº¦
                    vel_z = -0.15

                    # (å¯é€‰) è¶…æ—¶ä¿æŠ¤ï¼šå¦‚æœç›²é™äº† 3ç§’ è¿˜æ²¡åœæ¡¨(ä¹Ÿæ²¡è§¦åœ°)ï¼Œå°±æ‚¬åœæŠ¥è­¦
                    if blind_land_start_time == 0:
                        blind_land_start_time = time.time()
                    elif time.time() - blind_land_start_time > 3.0:
                        print("âŒ ç›²é™è¶…æ—¶ï¼æ‚¬åœï¼")
                        vel_z = 0.0
                    #å¯èƒ½å­˜åœ¨è¯†åˆ«ä¸åˆ°ä½†æ˜¯ä½ç½®å¾ˆé«˜çš„æƒ…å†µï¼Œ

            # --- D. å¼‚æ­¥å‘é€ ---
            send_data = {
                "r": float(cmd_pitch),
                "p": float(cmd_roll),
                "y": 0.0,
                "t": float(vel_z)
            }
            udp_sender.send_async(send_data)

            # --- E. æ˜¾ç¤º ---
            # ç¼©å°ä¸€ç‚¹æ˜¾ç¤ºï¼Œé˜²æ­¢å æ»¡å±å¹•
            show_frame = cv2.resize(frame, (960, 540))
            # æ˜¾ç¤º FPS
            fps = 1.0 / max(dt, 0.001)
            cv2.putText(show_frame, f"FPS: {fps:.1f}", (20, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            cv2.imshow("M3E Fusion Control", show_frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

    except KeyboardInterrupt:
        pass
    finally:
        print("ğŸ›‘ æ­£åœ¨åœæ­¢çº¿ç¨‹...")
        stream_loader.stop()
        udp_sender.stop()
        cv2.destroyAllWindows()


if __name__ == "__main__":
    main()