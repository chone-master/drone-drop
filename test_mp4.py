import cv2
import cv2.aruco as aruco
import numpy as np
import time
import math
import socket
import json
import threading

# ================= 1. ç”¨æˆ·é…ç½®åŒºåŸŸ (æ¥è‡ªæ—§ä»£ç ) =================
# è§†é¢‘è·¯å¾„ (ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„)
VIDEO_PATH = "test2.mp4"
# VIDEO_PATH = 0  # å¦‚æœéœ€è¦ä½¿ç”¨æ‘„åƒå¤´ï¼Œè¯·å–æ¶ˆæ³¨é‡Šæ­¤è¡Œ

# ç½‘ç»œé…ç½® (Android ç«¯ IP)
ANDROID_IP = "192.168.42.129"
ANDROID_PORT = 8888

# ç‰©ç†å°ºå¯¸é…ç½® (å•ä½: ç±³)
TAG_SIZE_BIG = 0.515  # å¤§ç 
TAG_SIZE_SMALL = 0.096  # å°ç 

# Tag å¸ƒå±€åç§»é‡ (ID -> [x, y, z])
# 0å·æ˜¯å¤§ç ä¸­å¿ƒï¼Œ576/571æ˜¯å‘¨å›´å°ç 
TAG_LAYOUT = {
    0: np.array([0.0, 0.0, 0.0]),
    576: np.array([0.15, -0.15, 0.0]),
    571: np.array([-0.15, 0.15, 0.0])
}

# å¤„ç†åˆ†è¾¨ç‡ (å»ºè®®ä¸è¦ç”¨4Kè·‘å¤„ç†ï¼Œ1920x1080è¶³å¤Ÿä¸”æ›´å¿«)
PROCESS_W = 1920
PROCESS_H = 1080
DFOV_DEG = 84.0  # DJI è§†è§’


# ================= 2. å¤šçº¿ç¨‹è§†é¢‘æµç±» (æ–°å¢) =================
class CameraStream:
    """
    ä½¿ç”¨ç‹¬ç«‹çº¿ç¨‹è¯»å–è§†é¢‘æµï¼Œæ€»æ˜¯ä¿æŒæœ€æ–°çš„ä¸€å¸§ã€‚
    è§£å†³ cv2.VideoCapture ç¼“å†²åŒºå¯¼è‡´çš„å»¶è¿Ÿé—®é¢˜ã€‚
    """

    def __init__(self, src=0, width=1920, height=1080):
        self.stream = cv2.VideoCapture(src)
        self.stream.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.stream.set(cv2.CAP_PROP_FRAME_HEIGHT, height)

        if not self.stream.isOpened():
            print("âŒ é”™è¯¯ï¼šæ— æ³•æ‰“å¼€è§†é¢‘æº")
            self.stopped = True
        else:
            self.stopped = False

        self.ret, self.frame = self.stream.read()
        self.width = width
        self.height = height

    def start(self):
        """å¼€å¯å­çº¿ç¨‹"""
        if self.stopped: return self
        threading.Thread(target=self.update, args=(), daemon=True).start()
        return self

    def update(self):
        """åå°çº¿ç¨‹å¾ªç¯è¯»å–"""
        while not self.stopped:
            ret, frame = self.stream.read()
            if not ret:
                self.stopped = True
                break
            # åªä¿ç•™æœ€æ–°å¸§
            self.ret, self.frame = ret, frame
            time.sleep(0.005)  # ç¨å¾®ä¼‘çœ é¿å…å æ»¡CPU

    def read(self):
        """ä¸»çº¿ç¨‹è·å–å½“å‰å¸§"""
        return self.ret, self.frame

    def stop(self):
        self.stopped = True
        self.stream.release()


# ================= 3. PID æ§åˆ¶å™¨ (æ¥è‡ªæ–°ä»£ç ) =================
class PIDController:
    def __init__(self, kp, ki, kd, max_out=1.0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.max_out = max_out
        self.prev_error = 0
        self.integral = 0
        self.last_time = time.time()

    def update(self, error):
        current_time = time.time()
        dt = current_time - self.last_time
        if dt <= 0: dt = 0.033

        # P é¡¹
        p_term = self.kp * error

        # I é¡¹ (å¸¦é™å¹…ï¼Œé˜²æ­¢ç§¯åˆ†é¥±å’Œ - æ–°ä»£ç ç‰¹æ€§)
        self.integral += error * dt
        self.integral = np.clip(self.integral, -1.0, 1.0)
        i_term = self.ki * self.integral

        # D é¡¹
        d_term = self.kd * (error - self.prev_error) / dt

        output = p_term + i_term + d_term
        self.prev_error = error
        self.last_time = current_time

        return np.clip(output, -self.max_out, self.max_out)


# ================= 4. å¢å¼ºå‹ Tag æ£€æµ‹å™¨ =================
class EnhancedTagDetector:
    def __init__(self, width, height, dfov_deg):
        # åˆå§‹åŒ–ç›¸æœºå†…å‚
        self.camera_matrix, self.dist_coeffs = self._get_camera_matrix(width, height, dfov_deg)

        # åˆå§‹åŒ– ArUco
        self.aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_APRILTAG_36h11)
        self.parameters = aruco.DetectorParameters()
        # è¿™é‡Œæˆ‘ä¾ç„¶å»ºè®®åŠ ä¸Š subpixï¼Œå¯¹æ€§èƒ½å½±å“å¾ˆå°ä½†ç²¾åº¦é«˜
        self.parameters.cornerRefinementMethod = aruco.CORNER_REFINE_SUBPIX
        self.detector = aruco.ArucoDetector(self.aruco_dict, self.parameters)

    def _get_camera_matrix(self, width, height, dfov_deg):
        diagonal_pixels = math.sqrt(width ** 2 + height ** 2)
        fov_rad = math.radians(dfov_deg)
        f_px = (diagonal_pixels / 2) / math.tan(fov_rad / 2)
        K = np.array([[f_px, 0, width / 2], [0, f_px, height / 2], [0, 0, 1]], dtype=np.float32)
        D = np.zeros((5, 1))
        return K, D

    def detect_with_enhancement(self, frame):
        """é€»è¾‘æ ¸å¿ƒï¼šæ™®é€šæ£€æµ‹ -> å£ç½©æ³• -> è†¨èƒ€æ³•"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # 1. æ­£å¸¸æ£€æµ‹
        corners, ids, _ = self.detector.detectMarkers(gray)
        final_corners = list(corners) if corners else []
        final_ids = list(ids[:, 0]) if ids is not None else []

        has_big_tag = 0 in final_ids if final_ids else False

        # 2. å¦‚æœæ²¡æ‰¾åˆ°å¤§ç ï¼Œå°è¯•â€œæ‰‹æœ¯å£ç½©æ³•â€
        if not has_big_tag:
            corners_mask, ids_mask = self._mask_small_tags_method(gray, final_corners, final_ids)
            if ids_mask is not None and 0 in ids_mask:
                final_corners.extend(corners_mask)
                final_ids.extend(ids_mask[:, 0])
                has_big_tag = True
                # print("ğŸ’¡ è§¦å‘ä¿®æ­£ï¼šæ‰‹æœ¯å£ç½©æ³•")

        # 3. å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•â€œè†¨èƒ€æ³•â€
        if not has_big_tag:
            corners_dilate, ids_dilate = self._dilate_method(gray)
            if ids_dilate is not None and 0 in ids_dilate:
                final_corners.extend(corners_dilate)
                final_ids.extend(ids_dilate[:, 0])
                has_big_tag = True
                # print("ğŸ’¡ è§¦å‘ä¿®æ­£ï¼šå›¾åƒè†¨èƒ€æ³•")

        if not final_ids:
            return tuple(), None

        return tuple(final_corners), np.array(final_ids).reshape(-1, 1)

    def _mask_small_tags_method(self, gray, existing_corners, existing_ids):
        """é®ç›–å·²çŸ¥å°ç åŒºåŸŸ"""
        masked_gray = gray.copy()
        small_tags_corners = []
        if existing_ids:
            for i, id_val in enumerate(existing_ids):
                if id_val in [571, 576]:  # å°ç ID
                    small_tags_corners.append(existing_corners[i])

        for corner_set in small_tags_corners:
            pts = corner_set[0]
            center = np.mean(pts, axis=0)
            expanded_pts = (pts - center) * 1.6 + center  # æ‰©å¤§é®ç›–èŒƒå›´
            cv2.fillPoly(masked_gray, [expanded_pts.astype(np.int32)], 255)  # æ¶‚ç™½

        corners, ids, _ = self.detector.detectMarkers(masked_gray)
        if ids is not None and 0 in ids:
            idx = np.where(ids == 0)[0][0]
            return [corners[idx]], np.array([[0]])
        return None, None

    def _dilate_method(self, gray):
        """å›¾åƒè†¨èƒ€ä¿®å¤æ–­è£‚è¾¹æ¡†"""
        k_size = int(gray.shape[1] * 0.015)  # åŠ¨æ€æ ¸å¤§å°
        if k_size % 2 == 0: k_size += 1
        kernel = np.ones((k_size, k_size), np.uint8)
        dilated = cv2.dilate(gray, kernel, iterations=1)

        corners, ids, _ = self.detector.detectMarkers(dilated)
        if ids is not None and 0 in ids:
            idx = np.where(ids == 0)[0][0]
            return [corners[idx]], np.array([[0]])
        return None, None

    def solve_position(self, corners, ids):
        """è®¡ç®—èåˆåçš„ç‰©ç†ä½ç½®"""
        if ids is None: return None

        positions = []
        for i, id_val in enumerate(ids[:, 0]):
            curr_id = int(id_val)
            # æ ¹æ®IDé€‰æ‹©å°ºå¯¸
            size = TAG_SIZE_SMALL if curr_id in [571, 576] else TAG_SIZE_BIG

            # å®šä¹‰3Dç‚¹
            obj_pts = np.array([
                [-size / 2, size / 2, 0], [size / 2, size / 2, 0],
                [size / 2, -size / 2, 0], [-size / 2, -size / 2, 0]
            ], dtype=np.float32)

            # PnPè§£ç®— (æ­¤å¤„æš‚ä¸ä½¿ç”¨ IPPE_SQUAREï¼Œéµç…§ä½ çš„æŒ‡ç¤ºä¸è€ƒè™‘æŠ–åŠ¨)
            _, rvec, tvec = cv2.solvePnP(obj_pts, corners[i], self.camera_matrix, self.dist_coeffs)

            # åæ ‡è½¬æ¢ï¼šå°†å±€éƒ¨åæ ‡è½¬ä¸ºé™è½æ¿ä¸­å¿ƒåæ ‡
            if curr_id in TAG_LAYOUT:
                pos_center = tvec.flatten() - TAG_LAYOUT[curr_id]
                positions.append(pos_center)

        if positions:
            return np.mean(positions, axis=0)  # å¤šç èåˆå–å¹³å‡
        return None


# ================= 5. ä¸»æ§åˆ¶ç³»ç»Ÿ (èåˆé€»è¾‘) =================
def main():
    # 1. åˆå§‹åŒ–é€šä¿¡
    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    print(f"ğŸ“¡ UDP ç›®æ ‡: {ANDROID_IP}:{ANDROID_PORT}")

    # 2. åˆå§‹åŒ–æ£€æµ‹å™¨ä¸PID
    detector = EnhancedTagDetector(PROCESS_W, PROCESS_H, DFOV_DEG)

    # PID å‚æ•°æ ¹æ®æ—§ä»£ç é€»è¾‘å¾®è°ƒ
    pid_roll = PIDController(kp=1.0, ki=0.0, kd=0.1, max_out=1.0)  # æ§åˆ¶å·¦å³(X)
    pid_pitch = PIDController(kp=1.0, ki=0.0, kd=0.1, max_out=1.0)  # æ§åˆ¶å‰å(Y)

    # 3. å¯åŠ¨å¤šçº¿ç¨‹è§†é¢‘æµ
    # æ³¨æ„ï¼šå¦‚æœæ˜¯æ–‡ä»¶ï¼ŒStreamThread ä¼šå¿«é€Ÿè¯»å®Œï¼Œé€‚åˆæ‘„åƒå¤´ã€‚æ–‡ä»¶æµ‹è¯•å»ºè®®ç”¨å•çº¿ç¨‹ã€‚
    # è¿™é‡Œä¸ºäº†æ»¡è¶³ä½ çš„â€œå¤šçº¿ç¨‹â€è¦æ±‚ï¼Œå¦‚æœæ˜¯æ–‡ä»¶ï¼Œæˆ‘ä»¬ç¨å¾®æ”¹ä¸€ç‚¹é€»è¾‘è®©å®ƒå¾ªç¯æ’­æ”¾
    camera = CameraStream(VIDEO_PATH, PROCESS_W, PROCESS_H).start()

    print("ğŸš€ ç³»ç»Ÿå¯åŠ¨ï¼ŒæŒ‰ 'q' é€€å‡º...")

    while True:
        # --- A. è·å–å›¾åƒ ---
        valid, frame = camera.read()
        if not valid:
            print("è§†é¢‘ç»“æŸæˆ–æ— æ³•è¯»å–")
            break

        # ç¡®ä¿åˆ†è¾¨ç‡ä¸€è‡´ (å¦‚æœæ˜¯4Kè¾“å…¥ï¼Œè¿™é‡Œä¼šç¼©æ”¾åˆ°1080På¤„ç†)
        if frame.shape[1] != PROCESS_W:
            frame = cv2.resize(frame, (PROCESS_W, PROCESS_H))

        # --- B. æ ¸å¿ƒè§†è§‰å¤„ç† (ä½¿ç”¨æ–°ä»£ç é€»è¾‘) ---
        corners, ids = detector.detect_with_enhancement(frame)
        final_pos = detector.solve_position(corners, ids)

        # é»˜è®¤æ§åˆ¶é‡
        cmd_roll = 0.0
        cmd_pitch = 0.0
        cmd_yaw = 0.0
        cmd_throttle = 0.0  # å¯¹åº” vel_z

        # --- C. æ§åˆ¶é€»è¾‘ ---
        if final_pos is not None:
            x, y, z = final_pos

            # è®¡ç®— PID (æ³¨æ„åæ ‡ç³»æ–¹å‘)
            # å‡è®¾ Xæ˜¯å·¦å³ï¼ŒYæ˜¯å‰åã€‚æ—§ä»£ç ï¼šupdate(0-x) * -1
            cmd_roll = pid_roll.update(0 - x) * -1
            cmd_pitch = pid_pitch.update(0 - y)

            # ä¸‹é™ç­–ç•¥ (æ–°ä»£ç çš„é€»è¾‘ï¼šå…ˆå¯¹å‡†ï¼Œå†ä¸‹é™)
            horizontal_error = math.sqrt(x ** 2 + y ** 2)
            if horizontal_error < 0.2:  # è¯¯å·®å°äº20cm
                cmd_throttle = -0.3  # ä¸‹é™
                status_text = "DESCENDING"
            else:
                cmd_throttle = 0.0  # æ‚¬åœå¯¹å‡†
                status_text = "ALIGNING"

            # ç»˜åˆ¶å¯è§†åŒ–
            aruco.drawDetectedMarkers(frame, corners, ids)
            # ç”»ä¸­å¿ƒç‚¹
            cx = int(PROCESS_W / 2 + x * (detector.camera_matrix[0][0] / z))
            cy = int(PROCESS_H / 2 + y * (detector.camera_matrix[1][1] / z))
            cv2.circle(frame, (cx, cy), 15, (0, 0, 255), -1)
            cv2.line(frame, (PROCESS_W // 2, PROCESS_H // 2), (cx, cy), (0, 255, 0), 2)

            # æ˜¾ç¤ºæ•°æ®
            cv2.putText(frame, f"H: {z:.2f}m | {status_text}", (30, 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(frame, f"ERR: X={x:.2f} Y={y:.2f}", (30, 100),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

        else:
            # ä¸¢å¤±ç›®æ ‡ï¼šæ‚¬åœ
            cv2.putText(frame, "SEARCHING...", (PROCESS_W // 2 - 100, PROCESS_H // 2),
                        cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)

        # --- D. å‘é€ UDP (æ—§ä»£ç æ ¼å¼) ---
        send_data = {
            "r": float(cmd_roll),
            "p": float(cmd_pitch),
            "y": float(cmd_yaw),
            "t": float(cmd_throttle)
        }

        try:
            msg = json.dumps(send_data).encode('utf-8')
            udp_socket.sendto(msg, (ANDROID_IP, ANDROID_PORT))
            # print(f"Sent: {send_data}")
        except Exception as e:
            print(f"UDP Error: {e}")

        # --- E. æ˜¾ç¤ºç”»é¢ ---
        # ç¼©å°æ˜¾ç¤ºä»¥ä¾¿åœ¨å±å¹•ä¸ŠæŸ¥çœ‹
        show_frame = cv2.resize(frame, (960, 540))
        cv2.imshow("Drone Vision", show_frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # æ¸…ç†
    camera.stop()
    udp_socket.close()
    cv2.destroyAllWindows()


if __name__ == "__main__":
    main()